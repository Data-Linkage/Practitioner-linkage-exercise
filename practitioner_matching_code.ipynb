{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Linkage Training Course\n",
    "\n",
    "We have two datasets which we want to link **practitioner_large_file** & **practitioner_small_file**:\n",
    "\n",
    "- **practitioner_large_file** contains the variables `IDA`, `Sex`, `Locality`, `Yearbirth`, `Monthbirth`, `Daybirth`, `Name` and a record ID that is contained in the variable `Bident`. In addition, there is a variable `Aident` that contains the record ID from the small file that it is matched to, i.e. we know the true match status.\n",
    "\n",
    "- **practitioner_small_file** contains the variables `IDB`, `Sex`, `Locality`, `Yearbirth`, `Monthbirth`, `Daybirth`, `Name` and a record ID that is contained in the variable `Aident`. In addition there is a variable, `Bident`, that contains the record ID from the large file that it is matched to, i.e. we know the true match status.\n",
    "\n",
    "Some of the variables in the **practitioner_small_file** were perturbed to simulate measurement errors. These are called `Sexpert`, `Yearbirthpert`, `Monthbirthpert`, `Daybirthpert`, `Namepert`. `Locality` was not perturbed and we will use this as a blocking variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas for data manipulation os to read the working directory\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Modify the settings so any variable or statement on its own line is displayed\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Widen output display\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "def get_file_path():\n",
    "    # This is the filepath where the datasets and the matchkey file can be found\n",
    "    file_path = os.getcwd()\n",
    "    return file_path\n",
    "\n",
    "# Read in datasets to link. Get the filepath from the command line arguments\n",
    "filepath = get_file_path()\n",
    "\n",
    "dfA = pd.read_csv(filepath + '/practitioner_large_file.csv') # 1,000 rows\n",
    "dfB = pd.read_csv(filepath + '/practitioner_small_file.csv') # 680 rows\n",
    "\n",
    "# Make sure column types correct\n",
    "dfA = dfA.astype({\"SEX_A\": float,\n",
    "                  \"locality_A\": float,\n",
    "                  \"yearbirth_A\": float,\n",
    "                  \"monthbirth_A\": float,\n",
    "                  \"daybirth_A\": float,\n",
    "                  \"Name_A\": str})\n",
    "    \n",
    "dfB = dfB.astype({\"SEX_B\": float,\n",
    "                  \"locality_B\": float,\n",
    "                  \"yearbirth_B\": float,\n",
    "                  \"monthbirth_B\": float,\n",
    "                  \"daybirth_B\": float,\n",
    "                  \"Name_B\": str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the columns headings and first 20 rows\n",
    "dfA.head(20)\n",
    "dfB.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Exact Match using the unperturbed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert name variables in both datasets to uppercase before exact match\n",
    "dfA['Name_A'] = dfA['Name_A'].str.upper()\n",
    "dfB['Name_B'] = dfB['Name_B'].str.upper()\n",
    "\n",
    "# Exact match (inner join - links records from dfA and dfB if they agree on all the \n",
    "# variables we are using for matching, in this case sex, locality, year, month and day of birth and name)\n",
    "# Think of the inner part of a venn diagram.\n",
    "linked_df = dfA.merge(dfB,\n",
    "                      left_on = ['SEX_A', 'locality_A', 'yearbirth_A', 'monthbirth_A', 'daybirth_A', 'Name_A'],\n",
    "                      right_on = ['SEX_B', 'locality_B', 'yearbirth_B', 'monthbirth_B', 'daybirth_B', 'Name_B'],\n",
    "                      how = 'inner')\n",
    "\n",
    "# Check the length of the linked dataset\n",
    "print('Number of records matched: ',len(linked_df))\n",
    "\n",
    "# Examine the residuals (outer join - gives us the records from dfA and dfB that do not\n",
    "# agree on all of the matching variables). Think of the outer circles in a venn diagram.\n",
    "residuals = dfA.merge(dfB,\n",
    "                      left_on = ['SEX_A', 'locality_A', 'yearbirth_A', 'monthbirth_A', 'daybirth_A', 'Name_A'],\n",
    "                      right_on = ['SEX_B', 'locality_B', 'yearbirth_B', 'monthbirth_B', 'daybirth_B', 'Name_B'],\n",
    "                      how = 'outer',\n",
    "                      indicator = True)\n",
    "\n",
    "# Check residuals (i.e. records that do not have a match) from dfA\n",
    "residualsA = residuals[residuals['_merge'] == 'left_only'] \n",
    "print('Number of unmatched records in dataframeA: ',len(residualsA))\n",
    "\n",
    "# Check residuals from dfB\n",
    "residualsB = residuals[residuals['_merge'] == 'right_only'] \n",
    "print('Number of unmatched records in dataframeB: ',len(residualsB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, all 680 records from the smaller dataset (`dfB`) linked to the larger dataset (`dfA`), as we have used the unperturbed variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Exact Match using the perturbed variables of `dfB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert peturbed name variable for dfB to uppercase before exact match\n",
    "dfB['namepert_B'] = dfB['namepert_B'].str.upper()\n",
    "\n",
    "# Exact match (inner join) using same variables (perturbed)\n",
    "linked_df2 = dfA.merge(dfB,\n",
    "                       left_on =  ['SEX_A', 'locality_A', 'yearbirth_A', 'monthbirth_A', 'daybirth_A', 'Name_A'],\n",
    "                       right_on = ['sexpert_B', 'locality_B', 'yearbirthpert_B', 'monthbirthpert_B', 'daybirthpert_B', 'namepert_B'],\n",
    "                       how = 'inner')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Examine the residuals\n",
    "residuals2 = dfA.merge(dfB,\n",
    "                       left_on =  ['SEX_A', 'locality_A', 'yearbirth_A', 'monthbirth_A', 'daybirth_A', 'Name_A'],\n",
    "                       right_on = ['sexpert_B', 'locality_B', 'yearbirthpert_B', 'monthbirthpert_B', 'daybirthpert_B', 'namepert_B'],\n",
    "                       how = 'outer',\n",
    "                      indicator = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that there were no unmatched records in `dfB` before. How many are there now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check residuals from dfB\n",
    "residualsB = residuals2[residuals2['_merge'] == 'right_only'] \n",
    "print('Number of unmatched records in dataframeB: ',len(residualsB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, 175 records from the smaller dataset (`dfB`) did not link to a record in the larger dataset (`dfA`) due to errors in the data. Let's have a look at the residuals from `dfB` to see what types of errors caused names not to be matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View names of clean & perturbed dataset B residuals - errors may have prevented exact match\n",
    "residualsB[['Name_B', 'namepert_B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of errors in the data can you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Clean the data by parsing names into two where appropriate and stripping off titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the name variables in both datasets. For example 'John Smith' would be split into two variables `name1` and `name2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two new columns name1 and name2, by splitting the name column by the delimiter ' '\n",
    "# Name2 will be 'None' if there was only one name\n",
    "# For dfB use namepert instead of name\n",
    "dfA[['Name1_A', 'Name2_A']] = dfA['Name_A'].str.split(' ',expand=True)\n",
    "dfB[['Name1pert_B', 'Name2pert_B']] = dfB['namepert_B'].str.split(' ',expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete redundant words. In this case, we only have first names in the file. There are prefixes that appear in the dataset, such as: Mr. Smith or Mrs. Smith. Since we only have one field for name in the dataset, we will delete the redundant word and put the more ‘relevant’ name in  that  field. In this  simple case, the only redundant words in our datasets  are ‘MR’ and  ‘MRS’, so we will simply use a `where` / `if-else` statement in the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap Name 1 and Name 2 if Name 1 is Mr or Mrs\n",
    "import numpy as np\n",
    "dfA['Name1_A'], dfA['Name2_A'] = np.where((dfA['Name1_A'] == 'MR') | (dfA['Name1_A'] == 'MRS'), [dfA['Name2_A'], dfA['Name1_A']], [dfA['Name1_A'], dfA['Name2_A']])\n",
    "dfB['Name1pert_B'], dfB['Name2pert_B'] = np.where((dfB['Name1pert_B'] == 'MR') | (dfB['Name1pert_B'] == 'MRS'), [dfB['Name2pert_B'], dfB['Name1pert_B']], [dfB['Name1pert_B'], dfB['Name2pert_B']])\n",
    "\n",
    "# Set Name 2 to missing if it is Mr or Mrs\n",
    "dfA['Name2_A'] = np.where((dfA['Name2_A'] == 'MR') | (dfA['Name2_A'] == 'MRS'), None, dfA['Name2_A'])\n",
    "dfB['Name2pert_B'] = np.where((dfB['Name2pert_B'] == 'MR') | (dfB['Name2pert_B'] == 'MRS'), None, dfB['Name2pert_B'])\n",
    "\n",
    "# Have a look at dataframe A to check the changes we've made\n",
    "dfA[['Name1_A', 'Name2_A']].head(20)\n",
    "\n",
    "\n",
    "# Exact match (inner join) using the variables (perturbed) after cleaning\n",
    "linked_df3 = dfA.merge(dfB,\n",
    "                       left_on =  ['SEX_A', 'locality_A', 'yearbirth_A', 'monthbirth_A', 'daybirth_A', 'Name1_A'],\n",
    "                       right_on = ['sexpert_B', 'locality_B', 'yearbirthpert_B', 'monthbirthpert_B', 'daybirthpert_B', 'Name1pert_B'],\n",
    "                       how = 'inner')\n",
    "\n",
    "# Find the residuals\n",
    "residuals3 = dfA.merge(dfB,\n",
    "                       left_on =  ['SEX_A', 'locality_A', 'yearbirth_A', 'monthbirth_A', 'daybirth_A', 'Name1_A'],\n",
    "                       right_on = ['sexpert_B', 'locality_B', 'yearbirthpert_B', 'monthbirthpert_B', 'daybirthpert_B', 'Name1pert_B'],\n",
    "                       how = 'outer',\n",
    "                       indicator = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that there were 174 unmatched records in `dfB` before. How many are there now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check residuals from dfB\n",
    "residualsB = residuals3[residuals3['_merge'] == 'right_only']\n",
    "print('Number of unmatched records in dataframeB: ',len(residualsB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have improved things a little by cleaning the `name` strings. But there are still 167 unmatched records in `dfB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the residuals - what kind of errors in the data do we still have?\n",
    "residualsB[['Name_B', 'Name1pert_B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4a: Rule-Based Matching - Relax Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now we have used exact matching. If we relax the rules a little we should find more matches. But beware - we may also introduce some false positives. What happens if we relax the criteria for `name` to match to only insisting that the first three letters of `name` match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new columns containing only the first three letters of the name in each dataset\n",
    "dfA['Short_Name_A'] = dfA.Name1_A.str[0:3]\n",
    "dfB['Short_Name_B'] = dfB.Name1pert_B.str[0:3]\n",
    "\n",
    "# Join on the new Short Name variable and sex, locality and date of birth\n",
    "linked_df4a = dfA.merge(dfB,\n",
    "                       left_on =  ['SEX_A', 'locality_A', 'yearbirth_A', 'monthbirth_A', 'daybirth_A', 'Short_Name_A'],\n",
    "                       right_on = ['sexpert_B', 'locality_B', 'yearbirthpert_B', 'monthbirthpert_B', 'daybirthpert_B', 'Short_Name_B'],\n",
    "                       how = 'inner')\n",
    "\n",
    "\n",
    "\n",
    "# Find the residuals\n",
    "residuals4a = dfA.merge(dfB,\n",
    "                       left_on =  ['SEX_A', 'locality_A', 'yearbirth_A', 'monthbirth_A', 'daybirth_A', 'Short_Name_A'],\n",
    "                       right_on = ['sexpert_B', 'locality_B', 'yearbirthpert_B', 'monthbirthpert_B', 'daybirthpert_B', 'Short_Name_B'],\n",
    "                       how = 'outer',\n",
    "                       indicator = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that there were 167 unmatched records in `dfB` before. How many are there now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count residuals from dfB\n",
    "residualsB = residuals4a[residuals4a['_merge'] == 'right_only']\n",
    "print('Number of unmatched records in dataframeB: ',len(residualsB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we only have 115 unmatched records - BUT are all of the matches correct? Check to see if `IDA=IDB` for all\n",
    "the records in the linked dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column 'Match_Status' that has value 1 if the match is correct and 0 otherwise\n",
    "linked_df4a['Match_Status'] = np.where(linked_df4a['ID_A'] == linked_df4a['ID_B'],1,0)\n",
    "\n",
    "print('Number of correct matches: ', len(linked_df4a[linked_df4a['Match_Status']==1]))\n",
    "print('Number of false positives: ', len(linked_df4a[linked_df4a['Match_Status']==0]))\n",
    "\n",
    "# Examine the false positives\n",
    "FPs = linked_df4a[linked_df4a['Match_Status']==0]\n",
    "\n",
    "# View\n",
    "FPs[['SEX_A', 'sexpert_B',\n",
    "     'yearbirth_A', 'yearbirthpert_B',\n",
    "     'monthbirth_A', 'monthbirthpert_B',\n",
    "     'daybirth_A', 'daybirthpert_B',\n",
    "     'Name_A', 'namepert_B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four false positives. Go back to the start of step 4a and change the length of the `Short_Name_A` and `Short_Name_B`. What is the best length of string to use to find the most true positives with the least false positives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4b: Rule-Based Matching - Relax Date of Birth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we relax the criteria for date of birth. Up until now we have insisted that day, month and year all match exactly. Let's see what happens if we let day be a mismatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_df4b = dfA.merge(dfB,\n",
    "                       left_on =  ['SEX_A', 'locality_A', 'monthbirth_A','yearbirth_A',  'Name1_A'],\n",
    "                       right_on = ['sexpert_B', 'locality_B',  'monthbirthpert_B', 'yearbirthpert_B','Name1pert_B'],\n",
    "                       how = 'inner')\n",
    "\n",
    "# Find the residuals\n",
    "residuals4b = dfA.merge(dfB,\n",
    "                       left_on =  ['SEX_A', 'locality_A', 'monthbirth_A','yearbirth_A',  'Name1_A'],\n",
    "                       right_on = ['sexpert_B', 'locality_B',  'monthbirthpert_B', 'yearbirthpert_B','Name1pert_B'],\n",
    "                       how = 'outer',\n",
    "                       indicator = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many residuals are there now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check residuals from dfB\n",
    "residualsB = residuals4b[residuals4b['_merge'] == 'right_only']\n",
    "print('Number of unmatched records in dataframeB: ',len(residualsB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of the matches are correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see if ID_A=ID_B for all the records in the linked dataset\n",
    "#Add a column 'Match_Status' that has value 1 if the match is correct and 0 otherwise\n",
    "linked_df4b['Match_Status'] = np.where(linked_df4b['ID_A'] == linked_df4b['ID_B'],1,0)\n",
    "\n",
    "print('Number of correct matches: ', len(linked_df4b[linked_df4b['Match_Status']==1]))\n",
    "print('Number of false positives: ', len(linked_df4b[linked_df4b['Match_Status']==0]))\n",
    "\n",
    "#Examine the false positives\n",
    "FPs = linked_df4b[linked_df4b['Match_Status']==0]\n",
    "\n",
    "# View\n",
    "FPs[['SEX_A', 'sexpert_B',\n",
    "     'yearbirth_A', 'yearbirthpert_B',\n",
    "     'monthbirth_A', 'monthbirthpert_B',\n",
    "     'daybirth_A', 'daybirthpert_B',\n",
    "     'Name_A', 'namepert_B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a false positive. Change the variables in the merges to see if we should remove a different, or another, date of birth variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - using Levenshtein edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function LD returns the Levenshtein edit distance between two strings\n",
    "def LD(s, t):\n",
    "    if s == \"\":\n",
    "        return len(t);\n",
    "    if t == \"\":\n",
    "        return len(s);\n",
    "    if s[-1] == t[-1]:\n",
    "        cost = 0\n",
    "    else:\n",
    "        cost = 1\n",
    "       \n",
    "    res = min([LD(s[:-1], t)+1,\n",
    "               LD(s, t[:-1])+1, \n",
    "               LD(s[:-1], t[:-1]) + cost])\n",
    "    return res;\n",
    "\n",
    "\n",
    "#Test the function by inputting some words of your choice\n",
    "string1=\"Rachel\"\n",
    "string2=\"Rachael\"\n",
    "print('Levenshtein Edit Distance [',string1,',',string2,'] = ',LD(string1, string2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `[Rachel, Rachael]` and `[Tim, Tom]` both have a `LD` score of 1. But one change in a three letter word is more significant than one change in a six letter word. To account for different name lengths, we'll also calculate a standardised Levenshtein Edit Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLD(s,t):\n",
    "    standardised = 1-(LD(s,t)/max(len(s),len(t)))\n",
    "    return standardised;\n",
    "\n",
    "string1=\"Rachel\"\n",
    "string2=\"Rachael\"\n",
    "print('Standardised Levenshtein Edit Distance [',string1,',',string2,'] = ',SLD(string1, string2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the Levenshtein distance as part of score based matching in Step 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First assume we don’t have a blocking variable. We will generate all possible pairs in the two datasets using the perturbed variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do this by creating two columns containing a single value and then join on that value\n",
    "dfA['join_col'] = 0\n",
    "dfB['join_col'] = 0\n",
    "\n",
    "# Produce all possible candidate pairs\n",
    "CP1 = dfA.merge(dfB,\n",
    "                on = 'join_col',\n",
    "                how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dfA` contains 1,000 records and `dfB` contains 680 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', len(CP1), 'possible pairs. Of these, 680 (0.1%) are true matches.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the blocking variable `locality`. This isn't perturbed hence we expect to retain all 680 true matches (and also find extra, false matches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce candidate pairs using blocking variable locality\n",
    "CP2 = dfA.merge(dfB,\n",
    "                left_on = 'locality_A',\n",
    "                right_on = 'locality_B',\n",
    "                how = 'left')\n",
    "\n",
    "print('There are', len(CP2), 'possible pairs. Of these, 680 (3.6%) are true matches.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Score Based Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign weights to the variables used for matching\n",
    "name_w=5\n",
    "sex_w=1\n",
    "day_w=2\n",
    "month_w=2\n",
    "year_w=3\n",
    "\n",
    "CP1['Score1']=(((CP1.Name1_A==CP1.Name1pert_B)*name_w)\n",
    "              +((CP1.SEX_A==CP1.sexpert_B)*sex_w)\n",
    "              +(((CP1.daybirth_A==CP1.daybirthpert_B) |(np.isnan(CP1.daybirth_A) & np.isnan(CP1.daybirthpert_B)))*day_w)\n",
    "              +(((CP1.monthbirth_A==CP1.monthbirthpert_B) | (np.isnan(CP1.monthbirth_A) & np.isnan(CP1.monthbirthpert_B)))*month_w)\n",
    "              +(((CP1.yearbirth_A==CP1.yearbirthpert_B) | (np.isnan(CP1.yearbirth_A) & np.isnan(CP1.yearbirthpert_B)))*year_w))             \n",
    "\n",
    "#This will tell us how many candidate pairs scored each of 0 (complete mismatch) to 13 (exact match)\n",
    "CP1.Score1.value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 513 exact matches as expected - the same as the number of residuals after `name` cleaning and exact matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP2['Score2']=(((CP2.Name1_A==CP2.Name1pert_B)*name_w)\n",
    "              +((CP2.SEX_A==CP2.sexpert_B)*sex_w)\n",
    "              +(((CP2.daybirth_A==CP2.daybirthpert_B) |(np.isnan(CP2.daybirth_A) & np.isnan(CP2.daybirthpert_B)))*day_w)\n",
    "              +(((CP2.monthbirth_A==CP2.monthbirthpert_B) | (np.isnan(CP2.monthbirth_A) & np.isnan(CP2.monthbirthpert_B)))*month_w)\n",
    "              +(((CP2.yearbirth_A==CP2.yearbirthpert_B) | (np.isnan(CP2.yearbirth_A) & np.isnan(CP2.yearbirthpert_B)))*year_w))                \n",
    "           \n",
    "\n",
    "#This will tell us how many candidate pairs scored each of 0 (complete mismatch) to 13 (exact match)\n",
    "CP2.Score2.value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the threshold for accepting as a match\n",
    "Threshold=10\n",
    "Matches = CP2[CP2['Score2'] >= Threshold]\n",
    "print('With threshold', Threshold, 'there are ',len(Matches), 'matches.')\n",
    "Matches.loc[:,'Match_Status']=np.where(Matches['ID_A'] == Matches['ID_B'],1,0)   # ignore warning\n",
    "\n",
    "# TP and FP\n",
    "print('Number of correct matches: ', len(Matches[Matches['Match_Status']==1]))\n",
    "print('Number of false positives: ', len(Matches[Matches['Match_Status']==0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the different scores tell us? You can alter the weights and threshold until you are happy that you have maximised true positives and minimised false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Score Based Matching with partial scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the Levenshtein Edit Distance to award a partial score for names that partially match. So names like Rachel and Rachael will score `0.857*name_w` rather than zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with blank space\n",
    "CP2['Name1_A'] = np.where(CP2['Name1_A'].isnull(), '', CP2['Name1_A'])\n",
    "CP2['Name1pert_B'] = np.where(CP2['Name1pert_B'].isnull(), '', CP2['Name1pert_B'])\n",
    "\n",
    "# Apply edit distance to pairs (warning - this takes about 12 minutes)\n",
    "CP2['SLD']=CP2.apply(lambda x: SLD(x['Name1_A'], x['Name1pert_B']), axis=1)\n",
    "\n",
    "# Calculate score\n",
    "CP2['Score2']=((CP2.SLD*name_w)\n",
    "              +((CP2.SEX_A==CP2.SEX_B)*sex_w)\n",
    "              +((CP2.daybirth_A==CP2.daybirthpert_B)*day_w)\n",
    "              +((CP2.monthbirth_A==CP2.monthbirthpert_B)*month_w)\n",
    "              +((CP2.yearbirth_A==CP2.yearbirthpert_B)*year_w))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Threshold=10\n",
    "Matches2 = CP2[CP2['Score2']>=Threshold]\n",
    "print('With threshold', Threshold ,'there are',len(Matches2), 'matches.')\n",
    "Matches2.loc[:,'Match_Status']=np.where(Matches2['ID_A'] == Matches2['ID_B'],1,0)\n",
    "\n",
    "# TP and FP\n",
    "print('Number of correct matches: ', len(Matches2[Matches2['Match_Status']==1]))\n",
    "print('Number of false positives: ', len(Matches2[Matches2['Match_Status']==0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the `Threshold` to see if you can make the false postive rate smaller."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
